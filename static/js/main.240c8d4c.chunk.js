(this["webpackJsonppersonal-website"]=this["webpackJsonppersonal-website"]||[]).push([[0],{212:function(e,t,i){},213:function(e,t,i){"use strict";i.r(t);var n=i(1),a=i(2),s=i.n(a),c=i(47),r=i.n(c),l=(i(84),i(11)),o=i(12),j=i(14),d=i(13),b=i(22),h=i(7),m=i(5),u=i(15),O=i.n(u),x=function(e){Object(j.a)(i,e);var t=Object(d.a)(i);function i(){return Object(l.a)(this,i),t.apply(this,arguments)}return Object(o.a)(i,[{key:"render",value:function(){return Object(n.jsx)("div",{children:Object(n.jsx)(O.a,{id:"about",children:Object(n.jsx)("section",{className:"colorlib-about","data-section":"about",id:"about",children:Object(n.jsx)("div",{className:"colorlib-narrow-content",children:Object(n.jsx)("div",{children:Object(n.jsxs)("div",{className:"col-md-12",children:[Object(n.jsx)(m.Animated,{animationIn:"bounceInLeft",animationOut:"fadeOut",isVisible:!0,animationInDuration:2e3,children:Object(n.jsx)("h2",{className:"colorlib-heading",style:{"font-size":"200%"},children:"About"})}),Object(n.jsx)(m.Animated,{animationIn:"fadeInUp",isVisible:!0,animationInDuration:2e3,children:Object(n.jsxs)("div",{style:{"font-size":"medium"},children:[Object(n.jsx)("p",{children:"My name is Muhammad Umair. I'm an undergraduate studying computer science in my senior year at Tufts University and expect to graduate in May 2021. This website is intended to serve as a showcase of my experiences as a programmer, the projects I've worked on, and my research interests. "}),Object(n.jsx)("p",{children:" From software engineering to DevOps to research, I'm primarily interested in solving problems in a dynamic, fast-paced, and challenging environment. "}),Object(n.jsx)("p",{children:"My research interests include Human Robot Interaction (HRI), an interdisciplinary field that emphasizes improving interaction between humans and robots. I'm particularly interested in incorporating human-like conversational features to improve dialogue-systems in robots."}),Object(n.jsx)("p",{children:"My overall goal is to aid in the development of technology that has a direct and observable impact on people's lives."})]})})]})})})})})})}}]),i}(a.Component),p=i(51),f=i(48),g=(i(144),function(e){Object(j.a)(i,e);var t=Object(d.a)(i);function i(){return Object(l.a)(this,i),t.apply(this,arguments)}return Object(o.a)(i,[{key:"render",value:function(){return Object(n.jsx)("div",{children:Object(n.jsxs)("aside",{id:"colorlib-aside",className:"border js-fullheight",children:[Object(n.jsxs)("div",{className:"text-center",children:[Object(n.jsx)("img",{className:"author-img",src:"/mumair01.github.io/images/about.jpg",alt:"About"}),Object(n.jsx)("h1",{id:"colorlib-main-menu",className:"colorlib-logo",children:"Muhammad Umair"}),Object(n.jsxs)("span",{className:"email",children:[Object(n.jsx)(f.a,{}),Object(n.jsx)("a",{href:"mailto:muhammad.umair@tufts.edu",target:"_blank",rel:"noreferrer",children:"muhammad.umair@tufts.edu"})]}),Object(n.jsxs)("span",{className:"email",children:[Object(n.jsx)(f.a,{}),Object(n.jsx)("a",{href:"mailto:umair.aarij@gmail.com",target:"_blank",rel:"noreferrer",children:"umair.aarij@gmail.com"})]})]}),Object(n.jsx)("div",{id:"colorlib-main-menu",role:"navigation",className:"navbar",children:Object(n.jsxs)("ul",{children:[Object(n.jsx)("li",{children:Object(n.jsx)("a",{href:"/#about",children:"About"})}),Object(n.jsx)("li",{children:Object(n.jsx)("a",{href:"/#interests",children:"Skills & Interests"})}),Object(n.jsx)("li",{children:Object(n.jsx)(b.b,{to:"/resume",children:"Resume / CV"})}),Object(n.jsx)("li",{children:Object(n.jsx)(b.b,{to:"/experience",children:"Experience"})}),Object(n.jsx)("li",{children:Object(n.jsx)(b.b,{to:"/projects",children:"Projects"})})]})}),Object(n.jsx)("div",{className:"text-center",children:Object(n.jsx)("nav",{id:"colorlib-main-menu",children:Object(n.jsxs)("ul",{children:[Object(n.jsx)("li",{children:Object(n.jsxs)("a",{href:"https://www.linkedin.com/in/mumair/",target:"_blank",rel:"noopener noreferrer",children:[Object(n.jsx)("i",{}),Object(n.jsx)(p.b,{})]})}),Object(n.jsx)("li",{children:Object(n.jsxs)("a",{href:"https://github.com/mumair01",target:"_blank",rel:"noopener noreferrer",children:[Object(n.jsx)("i",{}),Object(n.jsx)(p.a,{})]})})]})})}),Object(n.jsxs)("div",{className:"colorlib-footer",children:[Object(n.jsx)("p",{children:Object(n.jsx)("small",{children:"Muhammad Umair - Personal website"})}),Object(n.jsx)("p",{children:Object(n.jsx)("small",{children:"Muhammad Umair \xa9 2021"})})]})]})})}}]),i}(a.Component)),v=i(36),y=i(78),N=i(52),I=i(6),w=(i(193),i(35)),k=i.n(w),A=(i(211),function(e){var t=e.rowData;return Object(n.jsx)("a",{href:t.section_link,children:t.name})}),T={columns:[{key:"name",title:"Project Names",dataType:I.DataType.String},{key:"keywords",title:"Keywords",dataType:I.DataType.String},{key:"affiliation",title:"Affiliation",dataType:I.DataType.String},{key:"dates",title:"Project dates",dataType:I.DataType.String}],data:[{name:"GailBot: An automated system for Conversation Analysis",keywords:"Python, NLP, ML, Statistical Modelling",affiliation:"Human Interaction Lab @ Tufts",dates:"May 2018 - Present",section_link:"#GailBot",section:"GailBot"},{name:"NextGen Alert System",keywords:"Python, React, Kibana, ElasticSearch",affiliation:"Tufts Technology Services (TTS)",dates:"Oct 2020 - Present",section_link:"#NextGen",section:"NextGen"},{name:"G-Meta Plus",keywords:"Graph Neural Networks, Meta-learning",dates:"Nov. 2020 - Jan. 2021",affiliation:"Deep Neural Networks @ Tufts University",section_link:"#g_meta_plus",section:"g_meta_plus"},{name:"GailBot: UI / UX design",keywords:"Frontend, UI/UX, Human Factors Engineering, PyQt5",affiliation:"Human Interaction Lab @ Tufts",dates:"Sept. 2020 - Jan. 2021",section_link:"#GailBot_UI_UX",section:"GailBot_UI_UX"},{name:"Camera calibration and distortion visualization",keywords:"OpenCV, Computer Vision, AI, ROS, PyQt5",affiliation:"Vicarious Surgical",dates:"May 2020 - Dec. 2020",section_link:"#camera_calibration",section:"camera_calibration"},{name:"Jeffersonize: CHAT/CAlite converter",keywords:"C++",affiliation:"Human Interaction Lab @ Tufts",dates:"July 2018 - Sept. 2018",section_link:"#jeffersonize",section:"jeffersonize"}],rowKeyField:"name",sortingMode:I.SortingMode.Single},M=function(){var e=Object(a.useState)(T),t=Object(y.a)(e,2),i=t[0],s=t[1];return Object(n.jsx)(N.Table,Object(v.a)(Object(v.a)({},i),{},{childComponents:{cellText:{content:function(e){switch(e.column.key){case"name":return Object(n.jsx)(A,Object(v.a)({},e))}}}},dispatch:function(e){s((function(t){return Object(N.kaReducer)(t,e)}))}}))};function C(e){return Object(n.jsx)("hr",{style:{color:e.color,backgroundColor:e.color,height:.5}})}var S=function(e){Object(j.a)(i,e);var t=Object(d.a)(i);function i(){return Object(l.a)(this,i),t.apply(this,arguments)}return Object(o.a)(i,[{key:"render",value:function(){return Object(n.jsxs)("div",{children:[Object(n.jsx)("section",{className:"colorlib-about",children:Object(n.jsx)(O.a,{id:"projects",children:Object(n.jsxs)("div",{className:"row col-md-12 colorlib-narrow-content",children:[Object(n.jsx)(m.Animated,{animationIn:"bounceInLeft",animationOut:"fadeOut",isVisible:!0,animationInDuration:2e3,children:Object(n.jsx)("h2",{className:"colorlib-heading",style:{"font-size":"200%"},children:"Projects"})}),Object(n.jsx)(m.Animated,{animationIn:"fadeInUp",isVisible:!0,animationInDuration:2e3,children:Object(n.jsx)(M,{})})]})})}),Object(n.jsx)("section",{className:"colorlib-about","data-section":"GailBot",children:Object(n.jsx)(O.a,{id:"GailBot",children:Object(n.jsx)("div",{className:"row col-md-12 colorlib-narrow-content",children:Object(n.jsxs)(m.Animated,{animationIn:"fadeInUp",isVisible:!0,animationInDuration:2e3,children:[Object(n.jsx)(C,{color:"black"}),Object(n.jsx)("h3",{className:"colorlib-heading",children:"GailBot: An automated transcription system for Conversation Analysis"}),Object(n.jsxs)("h3",{children:["Human Interaction Lab - Tufts University",Object(n.jsx)("br",{}),"May 2018 - Present"]}),"Motivation:",Object(n.jsxs)("ul",{children:[Object(n.jsx)("li",{children:"Develop an automated Speech To Text (STT) system that transcribes para-linguistic features of conversation, such as prosody, intonation, and laughter."}),Object(n.jsx)("li",{children:"This tool allows researchers in conversation analysis, human-robot interaction, and cognitive science to analyze interaction rather than focusing on data generation. "}),Object(n.jsx)("li",{children:" There is no existing tool that focuses on generating Jeffersonian transcripts by marking interesting features of conversation."})]}),"Role:",Object(n.jsxs)("ul",{children:[Object(n.jsx)("li",{children:" Designed and developed an automated speech to text system that uses novel statistical models to identify and transcribe para-linguistic features of conversation such as prosody, intonation, and laughter."}),Object(n.jsx)("li",{children:" Collaborated with graduate students at Tufts to identify important conversational features and recruited undergraduate interns to the development team."}),Object(n.jsxs)("li",{children:["Presented at ",Object(n.jsx)("a",{href:"https://amlap2020.org/",target:"_blank",rel:"noreferrer",children:" AMLAP 2020"})," and submitted to ",Object(n.jsx)("a",{href:"http://www.dialogue-and-discourse.org/",target:"_blank",rel:"noreferrer",children:"Dialogue and Discourse"})," as a ",Object(n.jsx)("a",{href:"https://osf.io/ap4s7/",target:"_blank",rel:"noreferrer",children:"first authored paper"}),", which is currently under review."]})]}),"Technical details:",Object(n.jsxs)("ul",{children:[Object(n.jsx)("li",{children:"Allows multi-language transcription through multiple speech to text engines, with custom language and custom acoustic models."}),Object(n.jsx)("li",{children:"Includes post-processing modules that include laughter detection, speech rate detection, and overlap detection. These can be easily extended to identify more complex conversational features."}),Object(n.jsx)("li",{children:"Uses threading to process utpo 1000 conversations in parallel."})]}),"Future goals:",Object(n.jsx)("ul",{children:Object(n.jsx)("li",{children:"A newer version of GailBot is currently under development and will feature multiple STT engines (IBM Watson, CMU Sphinx etc), a GUI interface, and audio segmentation for multi-speaker audio files."})}),"Collaborators:",Object(n.jsxs)("ul",{children:[Object(n.jsxs)("li",{children:[Object(n.jsx)("a",{href:"https://engineering.tufts.edu/people/faculty/jp-de-ruiter",target:"_blank",rel:"noreferrer",children:"J.P de Ruiter"}),"- PI of the Human Interaction Lab at Tufts"]}),Object(n.jsxs)("li",{children:[Object(n.jsx)("a",{href:"https://www.juliamertens.net/",target:"_blank",rel:"noreferrer",children:"Julia Mertens"})," - Miscommunication statistical modelling lead.",Object(n.jsx)("br",{})]}),Object(n.jsxs)("li",{children:[Object(n.jsx)("a",{href:"https://saulalbert.net/",target:"_blank",rel:"noreferrer",children:"Saul Albert"})," - Conversation Analysis expert"]})]}),"Additional Resources:",Object(n.jsxs)("ul",{children:[Object(n.jsx)("li",{children:Object(n.jsx)("a",{href:"https://github.com/HiLabTufts/GailBot",target:"_blank",rel:"noreferrer",children:"GailBot official release"})}),Object(n.jsxs)("li",{children:[Object(n.jsx)("a",{href:"https://sites.tufts.edu/hilab/files/2020/09/AMLAP-VIDEO.mp4",target:"_blank",rel:"noreferrer",children:"Poster presentation"})," by Julia Mertens and Muhammad Umair - AMLAP 2020"]}),Object(n.jsxs)("li",{children:[Object(n.jsx)("a",{href:"https://youtu.be/8dRXdPs5wRU",target:"_blank",rel:"noreferrer",children:"Three meeting points between Conversation Analysis and AI"})," by Saul Albert - ECCA 2020"]}),Object(n.jsx)("li",{children:Object(n.jsx)("a",{href:"https://sites.tufts.edu/hilab/",target:"_blank",rel:"noreferrer",children:"Human Interaction Lab at Tufts University"})})]}),Object(n.jsx)("br",{}),Object(n.jsx)(k.a,{url:"https://youtu.be/3Omp3aeuJf4"}),Object(n.jsx)(C,{color:"black"})]})})})}),Object(n.jsx)("section",{className:"colorlib-about","data-section":"NextGen",children:Object(n.jsx)(O.a,{id:"NextGen",children:Object(n.jsx)("div",{className:"row col-md-12 colorlib-narrow-content",children:Object(n.jsxs)(m.Animated,{animationIn:"fadeInUp",isVisible:!0,animationInDuration:2e3,children:[Object(n.jsx)(C,{color:"black"}),Object(n.jsx)("h3",{className:"colorlib-heading",children:"NextGen Alert System "}),Object(n.jsxs)("h3",{children:["Tufts Technology Services (TTS) - Tufts University",Object(n.jsx)("br",{}),"Oct. 2020 - Present"]}),Object(n.jsx)("p",{children:Object(n.jsx)("i",{children:"This project is conducted as part of the Senior Capstone requirement in the Computer Science department at Tufts university."})}),"Motivation:",Object(n.jsxs)("ul",{children:[Object(n.jsx)("li",{children:"TTS requires a Security and Event Management system, as an alternative to commercial software, that Provides real-time visualization, reporting, and alerting of ElasticSearch data clusters."}),Object(n.jsx)("li",{children:"A user interaction layer is needed to abstract specific endpoints, such as ElasticSearch and Kibana, away from the user."}),Object(n.jsx)("li",{children:"Need for a mechanism to send alerts through a pre-defined medium (such as email) based on results of queries to the cluster."})]}),"Role:",Object(n.jsxs)("ul",{children:[Object(n.jsx)("li",{children:"Designed a flask-based backend through collaboration with the entire team, with security and encryption as a primary concern."}),Object(n.jsx)("li",{children:"Developed a RESTful API to connect the frontend with backend endpoints, such as ElasticSearch and Kibana. "})]}),"Technical details:",Object(n.jsx)("ul",{children:Object(n.jsx)("li",{children:"Technical details are not publicly available. Please reach out for more information."})}),"Future goals:",Object(n.jsxs)("ul",{children:[Object(n.jsx)("li",{children:"Present the final product to TTS by May 2021."}),Object(n.jsx)("li",{children:"Incorporate machine learning techniques to analyze data trends in the cluster."})]}),"Collaborators:",Object(n.jsxs)("ul",{children:[Object(n.jsxs)("li",{children:[Object(n.jsx)("a",{href:"https://www.linkedin.com/in/andrew-wang-110102157/",target:"_blank",rel:"noreferrer",children:"Andrew Wang"})," - Developer"]}),Object(n.jsxs)("li",{children:[Object(n.jsx)("a",{href:"https://www.linkedin.com/in/kate-hanson-227359171/",target:"_blank",rel:"noreferrer",children:"Kate Hanson"})," - Developer"]}),Object(n.jsxs)("li",{children:[Object(n.jsx)("a",{href:"https://www.linkedin.com/in/james-cameron-718694190/",target:"_blank",rel:"noreferrer",children:"James Cameron"})," - Developer"]})]}),"Additional Resources:",Object(n.jsx)("ul",{children:Object(n.jsx)("li",{children:Object(n.jsx)("a",{href:"https://nextgenalerts.wordpress.com/",target:"_blank",rel:"noreferrer",children:"Engineering notebook for NextGen Alerts."})})}),Object(n.jsx)(C,{color:"black"})]})})})}),Object(n.jsx)("section",{className:"colorlib-about","data-section":"g_meta_plus",children:Object(n.jsx)(O.a,{id:"g_meta_plus",children:Object(n.jsx)("div",{className:"row col-md-12 colorlib-narrow-content",children:Object(n.jsxs)(m.Animated,{animationIn:"fadeInUp",isVisible:!0,animationInDuration:2e3,children:[Object(n.jsx)(C,{color:"black"}),Object(n.jsx)("h3",{className:"colorlib-heading",children:"G-Meta Plus"}),Object(n.jsxs)("h3",{children:["Deep Neural Networks - Tufts University",Object(n.jsx)("br",{}),"Nov. 2020 - Jan. 2021"]}),Object(n.jsx)("p",{children:Object(n.jsx)("i",{children:"This project started as the final project for Comp-137: Deep Neural Networks at Tufts university in Fall 2020."})}),"Motivation:",Object(n.jsxs)("ul",{children:[Object(n.jsx)("li",{children:"G-Meta, a model-agnostic meta-agnostic meta- learning method for fast adaptation of deep networks, can be improved by incorporating some global graph structure. It currently only incorporates local sub-graph structure."}),Object(n.jsx)("li",{children:"G-Meta uses Probabilistic Nearest Neighbor (PrNN) classification to make predictions. Our hypothesis is that we can replace PrNN with a more effective metric-learning technique. "})]}),"Role:",Object(n.jsxs)("ul",{children:[Object(n.jsx)("li",{children:"Provided theoretical justification of using subgraph relationships to incorporate global structure knowledge in G-Meta."}),Object(n.jsx)("li",{children:"Determined that a relation network would be a good replacement for the PrNN component of G-Meta. "}),Object(n.jsx)("li",{children:"Modified original G-Meta code to implement the changes described above and set up the architecture in Google Colab to train the model. "})]}),"Technical details:",Object(n.jsxs)("ul",{children:[Object(n.jsx)("li",{children:"Replaced PrNN with a relation network in G-Meta to train a function to compare support and query data."}),Object(n.jsx)("li",{children:"Incorporated shortest path between sub-graphs as one of the augmented features to incorporate global structure knowledge."}),Object(n.jsx)("li",{children:"Achieved an accuracy on node classification tasks (83%) that is two standard deviations higher than that of G-Meta (76%)."})]}),"Future goals:",Object(n.jsx)("ul",{children:Object(n.jsx)("li",{children:"We presented this project as part of the Comp-137: Deep Neural Networks course at Tufts university on Dec. 17th 2020. "})}),"Collaborators:",Object(n.jsxs)("ul",{children:[Object(n.jsxs)("li",{children:[Object(n.jsx)("a",{href:"https://www.linkedin.com/in/mert-erden-460007a8/",target:"_blank",rel:"noreferrer",children:"Mert Edren"})," - Tufts University"]}),Object(n.jsxs)("li",{children:[Object(n.jsx)("a",{href:"https://www.linkedin.com/in/gianmarcovisani/",target:"_blank",rel:"noreferrer",children:"Gian Marco Visani"})," - Tufts University"]})]}),"Additional Resources:",Object(n.jsxs)("ul",{children:[Object(n.jsx)("li",{children:Object(n.jsx)(b.b,{to:"/mumair01.github.io/docs/G-Meta-proposal.pdf",target:"_blank",children:"G-Meta plus original proposal "})}),Object(n.jsx)("li",{children:Object(n.jsx)("a",{href:"https://arxiv.org/abs/2006.07889",target:"_blank",rel:"noreferrer",children:"Graph Meta Learning via Local Subgraphs - Huang, Kexin and Zitnik, Marinka, NeurIPS, 2020"})})]}),Object(n.jsx)("br",{}),Object(n.jsx)(k.a,{url:"https://youtu.be/OQEPZb0R1jc"}),Object(n.jsx)(C,{color:"black"})]})})})}),Object(n.jsx)("section",{className:"colorlib-about","data-section":"GailBot_UI_UX",children:Object(n.jsx)(O.a,{id:"GailBot_UI_UX",children:Object(n.jsx)("div",{className:"row col-md-12 colorlib-narrow-content",children:Object(n.jsxs)(m.Animated,{animationIn:"fadeInUp",isVisible:!0,animationInDuration:2e3,children:[Object(n.jsx)(C,{color:"black"}),Object(n.jsx)("h3",{className:"colorlib-heading",children:"GailBot: UI / UX Design"}),Object(n.jsxs)("h3",{children:["Human Interaction Lab - Tufts University",Object(n.jsx)("br",{}),"Sept. 2020 - Jan. 2021"]}),"Motivation:",Object(n.jsxs)("ul",{children:[Object(n.jsx)("li",{children:"GailBot, an automated system for generating Jeffersonian transcripts, is currently a command line tool. It needs to be converted to a graphical user interface (GUI) for non-technical users."}),Object(n.jsx)("li",{children:"GUI needs to be based on feedback from the CA community, accessible, and abstract enough to integrate future components."})]}),"Role:",Object(n.jsxs)("ul",{children:[Object(n.jsx)("li",{children:"Supervised an internship to design of a CLI/GUI for GailBot using wireframes and user testing rounds."}),Object(n.jsx)("li",{children:"Implemented the design using the PyQt5 framework and integrated it into GailBot."})]}),"Technical details:",Object(n.jsxs)("ul",{children:[Object(n.jsx)("li",{children:"Incorporated feedback from multiple user testing rounds to create a functional GUI wireframe."}),Object(n.jsx)("li",{children:"Used PyQt5 to implement the GUI based on the model-view-controller design pattern, which separates the backend and frontend."})]}),"Future goals:",Object(n.jsx)("ul",{children:Object(n.jsx)("li",{children:"Complete the GUI implementation."})}),"Collaborators:",Object(n.jsx)("ul",{children:Object(n.jsxs)("li",{children:[Object(n.jsx)("a",{href:"https://evadenman.com/index.html",target:"_blank",rel:"noreferrer",children:"Eva Denman"})," - Lead designer / Intern @ the Tufts Human Interaction Lab"]})}),"Additional Resources:",Object(n.jsx)("ul",{children:Object(n.jsx)("li",{children:"Available on request."})}),Object(n.jsx)("br",{}),Object(n.jsx)(k.a,{url:"https://youtu.be/UbnOunPG4mU"}),Object(n.jsx)(C,{color:"black"})]})})})}),Object(n.jsx)("section",{className:"colorlib-about","data-section":"camera_calibration",children:Object(n.jsx)(O.a,{id:"camera_calibration",children:Object(n.jsx)("div",{className:"row col-md-12 colorlib-narrow-content",children:Object(n.jsxs)(m.Animated,{animationIn:"fadeInUp",isVisible:!0,animationInDuration:2e3,children:[Object(n.jsx)(C,{color:"black"}),Object(n.jsx)("h3",{className:"colorlib-heading",children:"Camera calibration and distortion visualization"}),Object(n.jsxs)("h3",{children:["Vicarious Surgical",Object(n.jsx)("br",{}),"May. 2020 - Dec. 2020"]}),"Motivation:",Object(n.jsxs)("ul",{children:[Object(n.jsx)("li",{children:"An internal tool is needed to ensure that there are no significant distortions in a visual input of a robot, and correct for these distortions if they exist."}),Object(n.jsx)("li",{children:"The tool needs to visualize the process through which it removed image distortions. This includes visualizing the detected calibration pattern, the detected corners, and the final error between the original and un-distorted images."}),Object(n.jsx)("li",{children:"The tool is required to be dockerized to be integrated into a larger pipeline. "})]}),"Role:",Object(n.jsxs)("ul",{children:[Object(n.jsx)("li",{children:"Developed a tool that uses RANSAC and blob detection detect calibration patterns and remove image distortions in real-time in a robot\u2019s visual input, and provides a full GUI implemented in PyQt5"}),Object(n.jsx)("li",{children:"Dockerized the tool and ROS environment to ensure cross-platform support."}),Object(n.jsx)("li",{children:"Integrated a component to provide various visualizations for errors between distorted and un-distorted images."})]}),"Technical details:",Object(n.jsxs)("ul",{children:[Object(n.jsx)("li",{children:"The tool was designed based on the Model View Controller (MVC) design pattern."}),Object(n.jsxs)("li",{children:["Used ",Object(n.jsx)("a",{href:"https://opencv.org/",target:"_blank",rel:"noreferrer",children:"OpenCV"})," to extract camera intrinsics/extrinsics and remove image distortions based on their value. "]}),Object(n.jsx)("li",{children:"Supports multiple calibration patterns as abstract entities."}),Object(n.jsx)("li",{children:"Further technical details are not publicly available. Please reach out for more information."})]}),"Future goals:",Object(n.jsx)("ul",{children:Object(n.jsx)("li",{children:"The project has been fully completed."})}),"Collaborators:",Object(n.jsx)("ul",{children:Object(n.jsxs)("li",{children:[Object(n.jsx)("a",{href:"https://engineering.tufts.edu/cs/people/faculty/fabrizio-santini",target:"_blank",rel:"noreferrer",children:"Fabrizio Santini"})," - Principal AI Engineer @ Vicarious Surgical"]})}),"Additional Resources:",Object(n.jsx)("ul",{children:Object(n.jsx)("li",{children:"Available on request."})}),Object(n.jsx)(C,{color:"black"})]})})})}),Object(n.jsx)("section",{className:"colorlib-about","data-section":"jeffersonize",children:Object(n.jsx)(O.a,{id:"jeffersonize",children:Object(n.jsx)("div",{className:"row col-md-12 colorlib-narrow-content",children:Object(n.jsxs)(m.Animated,{animationIn:"fadeInUp",isVisible:!0,animationInDuration:2e3,children:[Object(n.jsx)(C,{color:"black"}),Object(n.jsx)("h3",{className:"colorlib-heading",children:"Jeffersonize: CHAT/CAlite converter"}),Object(n.jsxs)("h3",{children:["Human Interaction Lab - Tufts University",Object(n.jsx)("br",{}),"July 2018 - Sept. 2018"]}),"Motivation:",Object(n.jsxs)("ul",{children:[Object(n.jsx)("li",{children:"There was a need to create a computer-readable version of the Conversation Analysis (CA) transcription format used by Conversation Analysts."}),Object(n.jsx)("li",{children:"This new computer-readable format needs to be integrated with the existing transcription format: CHAT."})]}),"Role:",Object(n.jsxs)("ul",{children:[Object(n.jsx)("li",{children:"Integrated new symbols into the existing transcription format, CA, to create CAlite."}),Object(n.jsx)("li",{children:"Designed and implemented Jeffersonize, a tool to enable bi-directional conversion between CHAT and CAlite."})]}),"Technical details:",Object(n.jsx)("ul",{children:Object(n.jsx)("li",{children:"The tool has an object-oriented design with a base class for shared conversion and sub-classes for bi-directional conversions."})}),"Future goals:",Object(n.jsx)("ul",{children:Object(n.jsx)("li",{children:"The project has been fully completed."})}),"Collaborators:",Object(n.jsx)("ul",{children:Object(n.jsxs)("li",{children:[Object(n.jsx)("a",{href:"https://saulalbert.net/",target:"_blank",rel:"noreferrer",children:"Saul Albert"})," - Project manager "]})}),"Additional Resources:",Object(n.jsxs)("ul",{children:[Object(n.jsx)("li",{children:Object(n.jsx)("a",{href:"https://github.com/mumair01/Jeffersonize",target:"_blank",rel:"noreferrer",children:"Jeffersonize repository"})}),Object(n.jsx)("li",{children:Object(n.jsx)("a",{href:"https://sites.tufts.edu/hilab/",target:"_blank",rel:"noreferrer",children:"Tufts Human Interaction Lab"})})]}),Object(n.jsx)(C,{color:"black"})]})})})})]})}}]),i}(a.Component),P=function(e){Object(j.a)(i,e);var t=Object(d.a)(i);function i(){return Object(l.a)(this,i),t.apply(this,arguments)}return Object(o.a)(i,[{key:"render",value:function(){return Object(n.jsx)("div",{children:Object(n.jsx)(O.a,{id:"interests",children:Object(n.jsx)("section",{className:"colorlib-about","data-section":"interests",children:Object(n.jsxs)("div",{className:"colorlib-narrow-content",children:[Object(n.jsx)("div",{className:"row",children:Object(n.jsx)("div",{className:"col-md-6 col-md-offset-3 col-md-pull-3 ",children:Object(n.jsx)(m.Animated,{animationIn:"bounceInLeft",animationOut:"fadeOut",isVisible:!0,animationInDuration:2e3,children:Object(n.jsx)("h2",{className:"colorlib-heading",style:{"font-size":"200%"},children:"Skills & Interests"})})})}),Object(n.jsx)("div",{className:"row row-pt-md",children:Object(n.jsxs)(m.Animated,{animationIn:"fadeInUp",isVisible:!0,animationInDuration:2e3,children:[Object(n.jsx)("div",{className:"col-md-5 text-center",children:Object(n.jsx)("div",{className:"services color-1",children:Object(n.jsxs)("div",{className:"desc",children:[Object(n.jsx)("h3",{children:"Programming Languages"}),Object(n.jsx)("p",{children:" These are some of the programming languages I am most familiar with:"}),Object(n.jsx)("p",{children:"Python \u2022 C \u2022 C++ \u2022 JavaScript \u2022 SQL \u2022 R \u2022 Racket \u2022 Smalltalk \u2022 TypeScript \u2022 MATLAB \u2022 VHDL"})]})})}),Object(n.jsx)("div",{className:"col-md-5 text-center",children:Object(n.jsx)("div",{className:"services color-1",children:Object(n.jsxs)("div",{className:"desc",children:[Object(n.jsx)("h3",{children:"Frameworks and tools"}),Object(n.jsx)("p",{children:"  These are some of the frameworks and tools I have used in my work:"}),Object(n.jsx)("p",{children:"ROS-2 \u2022 Flask \u2022 Docker \u2022 Jenkins \u2022 Hadoop \u2022 AWS \u2022 NodeJS \u2022 React \u2022 Django \u2022 Kubernetes \u2022 ElasticSearch \u2022 Kibana \u2022 Unity \u2022 Git \u2022 IntelliJ \u2022 Visual Studio"})]})})}),Object(n.jsx)("div",{className:"col-md-5 text-center",children:Object(n.jsx)("div",{className:"services color-1",children:Object(n.jsxs)("div",{className:"desc",children:[Object(n.jsx)("h3",{children:"Libraries"}),Object(n.jsx)("p",{children:"  These are important libraries that I have experience with:"}),Object(n.jsx)("p",{children:"OpenCV \u2022 PyQt5 \u2022 Tensorflow \u2022 Keras \u2022 PyTorch \u2022 Sickit \u2022 Numpy \u2022 Pandas \u2022 Matplotlib \u2022 Tkinter \u2022 ElasticSearch \u2022 Scipy \u2022 Twisted"})]})})}),Object(n.jsx)("div",{className:"col-md-5 text-center",children:Object(n.jsx)("div",{className:"services color-1",children:Object(n.jsxs)("div",{className:"desc",children:[Object(n.jsx)("h3",{children:"Natural Language Processing"}),Object(n.jsx)("p",{children:"One of my main projects, GailBot, is an automated transcription system that generates specialized transcripts to capture para-linguistic features of conversation, such as prosody and intonation. This involves using speech to text engines (IBM Watson, CMU Sphinx, Google cloud), dealing with large conversational corpora, and analyzing the data using natural language processing tool-kits."})]})})}),Object(n.jsx)("div",{className:"col-md-5 text-center",children:Object(n.jsx)("div",{className:"services color-1",children:Object(n.jsxs)("div",{className:"desc",children:[Object(n.jsx)("h3",{children:"Deep Learning and Artificial Intelligence (AI)"}),Object(n.jsx)("p",{children:" My experiences in industry and academia have given me the ability to apply machine learning techniques to real-world problems. For example, one of my projects is aimed at using deep learning to identify and label points of miscommunication in natural conversation. Another one improves an existing model-agnostic, meta-learning framework for Graph Neural Networks. I have also taken advanced ML and AI courses at Tufts university, including Intro. to AI, Intro. to ML and data mining, and deep neural networks."})]})})}),Object(n.jsx)("div",{className:"col-md-5 text-center",children:Object(n.jsx)("div",{className:"services color-1",children:Object(n.jsxs)("div",{className:"desc",children:[Object(n.jsx)("h3",{children:"DevOps"}),Object(n.jsx)("p",{children:"Most of my projects involve using an automated testing framework, such as Jenkins, and continuous integration techniques to ensure an efficient workflow."})]})})})]})})]})})})})}}]),i}(a.Component),U=function(e){Object(j.a)(i,e);var t=Object(d.a)(i);function i(){return Object(l.a)(this,i),t.apply(this,arguments)}return Object(o.a)(i,[{key:"render",value:function(){return Object(n.jsxs)("div",{children:[Object(n.jsx)("nav",{children:Object(n.jsx)("button",{children:Object(n.jsx)(b.b,{to:"/mumair01.github.io"+this.props.file,target:"_blank",download:!0,children:"Download"})})}),Object(n.jsx)("iframe",{title:"CV",src:"/mumair01.github.io"+this.props.file,style:{width:"90%",height:"600px",border:"2px solid black"}})]})}}]),i}(a.Component),D=function(e){Object(j.a)(i,e);var t=Object(d.a)(i);function i(){return Object(l.a)(this,i),t.apply(this,arguments)}return Object(o.a)(i,[{key:"render",value:function(){return Object(n.jsx)("div",{children:Object(n.jsx)("section",{className:"colorlib-about","data-section":"about",children:Object(n.jsx)(O.a,{id:"resume",children:Object(n.jsx)("div",{className:"colorlib-narrow-content",children:Object(n.jsx)("div",{children:Object(n.jsxs)("div",{className:"col-md-12",children:[Object(n.jsx)(m.Animated,{animationIn:"bounceInLeft",animationOut:"fadeOut",isVisible:!0,animationInDuration:2e3,children:Object(n.jsx)("h2",{className:"colorlib-heading",style:{"font-size":"200%"},children:"Resume / CV"})}),Object(n.jsx)(m.Animated,{animationIn:"fadeInUp",isVisible:!0,animationInDuration:2e3,children:Object(n.jsx)(U,{file:"/docs/Resume_Muhammad_Umair.pdf"})})]})})})})})})}}]),i}(a.Component),_=i(19),G=function(e){Object(j.a)(i,e);var t=Object(d.a)(i);function i(){return Object(l.a)(this,i),t.apply(this,arguments)}return Object(o.a)(i,[{key:"render",value:function(){return Object(n.jsxs)("div",{children:[Object(n.jsx)("section",{className:"colorlib-about",children:Object(n.jsx)(O.a,{id:"experience",children:Object(n.jsx)("div",{className:"row col-md-12 colorlib-narrow-content",children:Object(n.jsx)(m.Animated,{animationIn:"bounceInLeft",animationOut:"fadeOut",isVisible:!0,animationInDuration:2e3,children:Object(n.jsx)("h2",{className:"colorlib-heading",style:{"font-size":"200%"},children:"Experience"})})})})}),Object(n.jsxs)("section",{className:"colorlib-about","data-section":"Education experience",children:[Object(n.jsx)(m.Animated,{animationIn:"fadeInRight",animationInDuration:3e3,children:Object(n.jsx)("div",{className:"col-md-6 col-md-offset-3 col-md-pull-3",children:Object(n.jsx)("h2",{className:"colorlib-heading",children:"Education"})})}),Object(n.jsx)(m.Animated,{animationIn:"zoomIn",animationInDuration:3e3,children:Object(n.jsxs)("div",{className:"row col-md-12 timeline-centered",children:[Object(n.jsx)("article",{className:"timeline-entry",children:Object(n.jsx)("div",{className:"timeline-entry-inner",children:Object(n.jsxs)("div",{className:"timeline-label",children:[Object(n.jsx)(_.a,{}),Object(n.jsxs)("h2",{children:["Tufts University",Object(n.jsx)("br",{}),Object(n.jsx)("span",{children:" Medford, MA "}),Object(n.jsx)("br",{}),Object(n.jsx)("span",{children:" 2017 - Present (Expected 2021)"})]}),Object(n.jsx)("p",{children:"Pursuing a Bachelors of Science in Computer Science (BSCS) and minor in Cognitive Brain Science (CBS)"})]})})}),Object(n.jsx)("article",{className:"timeline-entry",children:Object(n.jsx)("div",{className:"timeline-entry-inner",children:Object(n.jsxs)("div",{className:"timeline-label",children:[Object(n.jsx)(_.a,{}),Object(n.jsxs)("h2",{children:["The City School - CCI",Object(n.jsx)("br",{}),Object(n.jsx)("span",{children:" Islamabad, Pakistan "}),Object(n.jsx)("br",{}),Object(n.jsx)("span",{children:" 2015 - 2017"})]}),Object(n.jsx)("p",{children:"Completed GCE O/A level qualifications"})]})})})]})})]}),Object(n.jsxs)("section",{className:"colorlib-about","data-section":"Technical experience current",children:[Object(n.jsx)(m.Animated,{animationIn:"fadeInRight",animationInDuration:3e3,children:Object(n.jsx)("div",{className:"col-md-6 col-md-offset-3 col-md-pull-3",children:Object(n.jsx)("h2",{className:"colorlib-heading",children:"Technical Experience - Current"})})}),Object(n.jsx)(m.Animated,{animationIn:"zoomIn",animationInDuration:3e3,children:Object(n.jsxs)("div",{className:"row col-md-12 timeline-centered",children:[Object(n.jsx)("article",{className:"timeline-entry",children:Object(n.jsx)("div",{className:"timeline-entry-inner",children:Object(n.jsxs)("div",{className:"timeline-label",children:[Object(n.jsx)(_.a,{}),Object(n.jsxs)("h2",{children:["Tufts Technology Services (TTS) - Student Employee",Object(n.jsx)("br",{}),Object(n.jsx)("span",{children:" Medford, MA "}),Object(n.jsx)("br",{}),Object(n.jsx)("span",{children:"Oct. 2020 - Present"})]}),Object(n.jsx)("p",{})]})})}),Object(n.jsx)("article",{className:"timeline-entry",children:Object(n.jsx)("div",{className:"timeline-entry-inner",children:Object(n.jsxs)("div",{className:"timeline-label",children:[Object(n.jsx)(_.a,{}),Object(n.jsxs)("h2",{children:["Tufts Human Interaction Lab - Lab Manager",Object(n.jsx)("br",{}),Object(n.jsx)("span",{children:" Medford, MA "}),Object(n.jsx)("br",{}),Object(n.jsx)("span",{children:"Jan. 2019 - Present"})]}),Object(n.jsx)("p",{})]})})})]})})]}),Object(n.jsxs)("section",{className:"colorlib-about","data-section":"Work experience",children:[Object(n.jsx)(m.Animated,{animationIn:"fadeInRight",animationInDuration:3e3,children:Object(n.jsx)("div",{className:"col-md-6 col-md-offset-3 col-md-pull-3",children:Object(n.jsx)("h2",{className:"colorlib-heading",children:"Technical Experience - Previous"})})}),Object(n.jsx)(m.Animated,{animationIn:"zoomIn",animationInDuration:3e3,children:Object(n.jsxs)("div",{className:"row col-md-12 timeline-centered",children:[Object(n.jsx)("article",{className:"timeline-entry",children:Object(n.jsx)("div",{className:"timeline-entry-inner",children:Object(n.jsxs)("div",{className:"timeline-label",children:[Object(n.jsx)(_.a,{}),Object(n.jsxs)("h2",{children:["Vicarious Surgical - Artificial Intelligence Intern",Object(n.jsx)("br",{}),Object(n.jsx)("span",{children:" Medford, MA "}),Object(n.jsx)("br",{}),Object(n.jsx)("span",{children:"May 2020 - Dec. 2020"})]}),Object(n.jsx)("p",{})]})})}),Object(n.jsx)("article",{className:"timeline-entry",children:Object(n.jsx)("div",{className:"timeline-entry-inner",children:Object(n.jsxs)("div",{className:"timeline-label",children:[Object(n.jsx)(_.a,{}),Object(n.jsxs)("h2",{children:["Tufts Human Interaction Lab - Research Intern",Object(n.jsx)("br",{}),Object(n.jsx)("span",{children:" Medford, MA "}),Object(n.jsx)("br",{}),Object(n.jsx)("span",{children:"May 2018 - Jan. 2019"})]}),Object(n.jsx)("p",{})]})})}),Object(n.jsx)("article",{className:"timeline-entry",children:Object(n.jsx)("div",{className:"timeline-entry-inner",children:Object(n.jsxs)("div",{className:"timeline-label",children:[Object(n.jsx)(_.a,{}),Object(n.jsxs)("h2",{children:["Tufts University - Teaching Assistant (computational design)",Object(n.jsx)("br",{}),Object(n.jsx)("span",{children:" Medford, MA "}),Object(n.jsx)("br",{}),Object(n.jsx)("span",{children:"May 2018 - Jan. 2019"})]})]})})}),Object(n.jsx)("article",{className:"timeline-entry",children:Object(n.jsx)("div",{className:"timeline-entry-inner",children:Object(n.jsxs)("div",{className:"timeline-label",children:[Object(n.jsx)(_.a,{}),Object(n.jsxs)("h2",{children:["Pakistan Aeronautical Complex (PAC) - Intern",Object(n.jsx)("br",{}),Object(n.jsx)("span",{children:" Kamra, Pakistan "}),Object(n.jsx)("br",{}),Object(n.jsx)("span",{children:"June 2016 - Aug. 2016"})]}),Object(n.jsx)("p",{})]})})})]})})]}),Object(n.jsxs)("section",{className:"colorlib-about","data-section":"Other experience",children:[Object(n.jsx)(m.Animated,{animationIn:"fadeInRight",animationInDuration:3e3,children:Object(n.jsx)("div",{className:"col-md-6 col-md-offset-3 col-md-pull-3",children:Object(n.jsx)("h2",{className:"colorlib-heading",children:"Other work experience"})})}),Object(n.jsx)(m.Animated,{animationIn:"zoomIn",animationInDuration:3e3,children:Object(n.jsxs)("div",{className:"row col-md-12 timeline-centered",children:[Object(n.jsx)("article",{className:"timeline-entry",children:Object(n.jsx)("div",{className:"timeline-entry-inner",children:Object(n.jsxs)("div",{className:"timeline-label",children:[Object(n.jsx)(_.a,{}),Object(n.jsxs)("h2",{children:["Tufts University Conference and Event Services - Summer Intern",Object(n.jsx)("br",{}),Object(n.jsx)("span",{children:" Medford, MA "}),Object(n.jsx)("br",{}),Object(n.jsx)("span",{children:"May 2019 - Sept. 2019"})]}),Object(n.jsx)("p",{})]})})}),Object(n.jsx)("article",{className:"timeline-entry",children:Object(n.jsx)("div",{className:"timeline-entry-inner",children:Object(n.jsxs)("div",{className:"timeline-label",children:[Object(n.jsx)(_.a,{}),Object(n.jsxs)("h2",{children:["Tufts University Career Center - Summer Office Assistant",Object(n.jsx)("br",{}),Object(n.jsx)("span",{children:" Medford, MA "}),Object(n.jsx)("br",{}),Object(n.jsx)("span",{children:"May 2018 - Sept. 2018"})]}),Object(n.jsx)("p",{})]})})}),Object(n.jsx)("article",{className:"timeline-entry",children:Object(n.jsx)("div",{className:"timeline-entry-inner",children:Object(n.jsxs)("div",{className:"timeline-label",children:[Object(n.jsx)(_.a,{}),Object(n.jsxs)("h2",{children:["Elliot Pearson's Children School - Administrative Assistant",Object(n.jsx)("br",{}),Object(n.jsx)("span",{children:" Medford, MA "}),Object(n.jsx)("br",{}),Object(n.jsx)("span",{children:"Jan. 2018 - May. 2019"})]}),Object(n.jsx)("p",{})]})})})]})})]})]})}}]),i}(a.Component),L=i(76),R=i(77),z=function(){return Object(n.jsx)("div",{className:"border",children:Object(n.jsx)(R.a,{speed:5,mode:"smooth",children:function(e){return Object(L.a)(e),Object(n.jsx)(n.Fragment,{children:Object(n.jsx)("p",{children:"Check out my latest project: Jeffersonize"})})}})})},V=(a.Component,i(212),function(){return Object(n.jsxs)("div",{children:[Object(n.jsx)(x,{}),Object(n.jsx)(P,{})]})}),J=function(e){Object(j.a)(i,e);var t=Object(d.a)(i);function i(){return Object(l.a)(this,i),t.apply(this,arguments)}return Object(o.a)(i,[{key:"render",value:function(){return Object(n.jsx)("div",{id:"colorlib-page",children:Object(n.jsx)("div",{id:"colorlib-wrap",children:Object(n.jsxs)(b.a,{basename:"/",children:[Object(n.jsx)(g,{}),Object(n.jsx)("div",{id:"colorlib-main",children:Object(n.jsxs)(h.c,{children:[Object(n.jsx)(h.a,{exact:!0,path:"/",component:V}),Object(n.jsx)(h.a,{path:"/projects",component:S}),Object(n.jsx)(h.a,{path:"/resume",component:D}),Object(n.jsx)(h.a,{path:"/experience",component:G}),Object(n.jsx)(h.a,{path:"/*",component:V})]})})]})})})}}]),i}(a.Component),B=function(e){e&&e instanceof Function&&i.e(3).then(i.bind(null,214)).then((function(t){var i=t.getCLS,n=t.getFID,a=t.getFCP,s=t.getLCP,c=t.getTTFB;i(e),n(e),a(e),s(e),c(e)}))};r.a.render(Object(n.jsx)(s.a.StrictMode,{children:Object(n.jsx)(J,{})}),document.getElementById("root")),B()},84:function(e,t,i){}},[[213,1,2]]]);
//# sourceMappingURL=main.240c8d4c.chunk.js.map